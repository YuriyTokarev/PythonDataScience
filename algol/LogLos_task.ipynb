{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, \n",
    "               1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)\n",
    "\n",
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res\n",
    "\n",
    "def calc_std_feat(x):\n",
    "    res = (x - x.mean()) / x.std()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  3.        ,\n",
       "         0.        ,  5.        , 10.        ,  1.        ,  2.        ],\n",
       "       [-0.97958969, -0.56713087, -0.46401617, -0.77336028,  0.97958969,\n",
       "        -0.36090146,  1.08270439,  2.11385144, -1.08270439,  0.05155735],\n",
       "       [ 1.        ,  1.        ,  2.        ,  1.        ,  2.        ,\n",
       "         1.        ,  3.        ,  3.        ,  1.        ,  2.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# отмасштабируем один из признаков\n",
    "X_st = X.copy()\n",
    "X_st[2, :] = calc_std_feat(X[2, :])\n",
    "\n",
    "X_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1: \n",
    "*Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Я не уверен, правильно ли я понял задание, но избежать мы можем просто сместив значение на минимальную величину\n",
    "# Введем параметр minEps, при y_pred==0 заменим y_pred на minEps, а при y_pred==1 на (1-minEps)\n",
    "# Естественно, подразумевается, что minEps примерно равна 0 и отличается от нее меньше значимого порядка предсказания\n",
    "\n",
    "def calc_logloss(y, y_pred, minEps = 1e-8):\n",
    "    \n",
    "    y_pred = np.where(y_pred==0, minEps, y_pred) \n",
    "    y_pred = np.where(y_pred==1, 1-minEps, y_pred) \n",
    "\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2: \n",
    "*Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        err = calc_logloss(y, y_pred)\n",
    "        W -= alpha * (1/n * np.dot(X, (y_pred - y).T))\n",
    "    print(i, W, err)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 [-292.17003934  -20.04019167  -87.04368153  222.4874873 ] 0.0023089657288500104\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=30000, alpha=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно это ошибка, но функция получилась убывающей. Мы можем до бесконечности приближаться к нулю увеличивая скорость обучения и количество иттераций.\n",
    "\n",
    "Остановился на скорости 40 (т.к. при большей скорости python не можемт посчитать exp) и количестве иттераций - 30000, чтобы время поиска было адекватное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 3: \n",
    "*Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(w, X):\n",
    "   \n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    y_pred_proba = sigmoid(np.dot(w.T, X))\n",
    "    \n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14794522e-02, 2.97114394e-18, 1.00000000e+00, 1.85750323e-10,\n",
       "        9.99399572e-01, 2.40028309e-17, 1.00000000e+00, 1.10885085e-04,\n",
       "        9.89226487e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = calc_pred_proba(W, X_st)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 4: \n",
    "*Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(w, X):\n",
    "    y_predicted = np.zeros((1, X.shape[1]))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    A = sigmoid(np.dot(w.T, X))\n",
    "    \n",
    "#     За порог отнесения к тому или иному классу примем вероятность 0.5\n",
    "    for i in range(A.shape[1]):\n",
    "        if (A[:,i] > 0.5): \n",
    "            y_predicted[:, i] = 1\n",
    "        elif (A[:,i] <= 0.5):\n",
    "            y_predicted[:, i] = 0\n",
    "    \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W, X_st)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 5: \n",
    "*Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    return np.sum(np.equal(y, y_pred)) / y.shape[0]\n",
    "\n",
    "\n",
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y=+1</th>\n",
       "      <th>y=-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred=+1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred=-1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y=+1  y=-1\n",
       "type               \n",
       "pred=+1     5     0\n",
       "pred=-1     0     5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def errorMatrix(y, y_pred):\n",
    "    Xor = np.logical_xor(y, y_pred)\n",
    "    Eq = np.logical_not(Xor)\n",
    "    \n",
    "    PPred = y_pred\n",
    "    NPred = np.logical_not(y_pred)\n",
    "\n",
    "    TP = np.sum(np.logical_and(PPred, Eq))\n",
    "    TN = np.sum(np.logical_and(NPred, Eq))\n",
    "    FP = np.sum(np.logical_and(PPred, Xor))\n",
    "    FN = np.sum(np.logical_and(NPred, Xor))\n",
    "    \n",
    "    return TP, FP, FN, TN\n",
    "\n",
    "TP, FP, FN, TN = errorMatrix(y, y_pred)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"y=+1\": [TP, FP],\n",
    "    \"y=-1\": [FN, TN],\n",
    "    \"type\": ['pred=+1', 'pred=-1']\n",
    "})\n",
    "df.set_index('type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6: \n",
    "*Могла ли модель переобучиться? Почему?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, модель скорее всего переобучилась, мы довели ошибку до минимума и в результате получили довольно высокие коэффициенты по первому и последнему признакам.\n",
    "\n",
    "А так как мы предварительно не отсеяли выбросы, то есть высокий риск, что именно они могли \"испортить\" нашу модель и привести к переобучению.\n",
    "\n",
    "Поэтому на проверочных данных точность скорее всего будет крайне низкая.\n",
    "\n",
    "Очевидно здесь нужно добавить регуляризацию.\n",
    "\n",
    "Либо вывести график изменения ошибки в зависимости от увеличения количества иттераций для разных скоростей обучения и останавливать обучение не на минимуме фукнции ошибки, а на \"сгибе\", т.е. моменте, когда увеличение обучения перестает давать существенный эффект (т.е. увеличение иттераций дает незначительное уменьшение ошибки). Поидее именно этот момент будет отделять обученную модель от переобученной.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
